{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cellId": "82oayy6p3m89igczfvzrnb",
    "id": "xrOtpM8UhGtd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cellId": "f2mhs86opulgvelxq7oblg",
    "id": "y2AihEGehGtj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "### Подготовка данных на вход сети\n",
    "\n",
    "protein_struct_loaded = pd.read_csv('protein_struct.csv')\n",
    "#protein_struct_loaded = protein_struct_loaded.head(20000)\n",
    "#protein_struct_loaded = protein_struct_loaded.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cellId": "3h4ozkxwk88n2j1ejw7zzl"
   },
   "outputs": [],
   "source": [
    "#protein_struct_loaded = protein_struct_loaded.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cellId": "1tdv3tw1qyv6hq87s7ls2u",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDf7lxnlg-tc",
    "outputId": "72cfbe81-91ae-45a9-8152-39f1d9e8f8ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25455"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_struct_loaded.protein_chain_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cellId": "wuneyle3q3as6la7m19o",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stHYrEediBIr",
    "outputId": "9900b88c-4ad3-4a4b-f1b8-98f662b1b373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct_class\n",
      "0         11\n",
      "1     169932\n",
      "3          6\n",
      "4          7\n",
      "5      59419\n",
      "10         1\n",
      "1       6179\n",
      "5       1687\n",
      "sh    242046\n",
      "Name: struct_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### y\n",
    "data = protein_struct_loaded[['protein_chain_id','protein_chain_sequence','struct_class','struct_sequence','init_seq_num','term_seq_num']]\n",
    "#data = data[(data.struct_class == '1') | (data.struct_class == '5') | (data.struct_class == 'sh')]\n",
    "\n",
    "#data.struct_class.unique()\n",
    "print(data.struct_class.groupby(data.struct_class).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cellId": "nhzbjb01thq1h497sbjfgo"
   },
   "outputs": [],
   "source": [
    "data1= data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cellId": "ds1jxkxi2j8x4dof36r8w"
   },
   "outputs": [],
   "source": [
    "data1['ccc'] = data1.term_seq_num - data1.init_seq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cellId": "9flnkg622jh2aci2nlommh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               count      sum\n",
      "struct_class                 \n",
      "0                 11       88\n",
      "1             169932  2076368\n",
      "3                  6       21\n",
      "4                  7       74\n",
      "5              59419   219777\n",
      "10                 1        6\n",
      "1               6179    76682\n",
      "5               1687     6104\n",
      "sh            242046  1081898\n"
     ]
    }
   ],
   "source": [
    "print(data1[['struct_class','ccc']].ccc.groupby(data1.struct_class).agg(('count', 'sum')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "cellId": "cx1jnxufzxn3l7uagzph8h"
   },
   "outputs": [],
   "source": [
    "helix1 = 2076368+76682\n",
    "helix5 = 219777+6104\n",
    "sheet = 1081898\n",
    "all = 25455*700\n",
    "other = all - helix1 - helix5 - sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cellId": "fuw45nkvnkapyzyg34rqp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2153050, 225881, 1081898, 14357671)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helix1,helix5,sheet, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cellId": "jbw7ouoxixjwpe4gz9l019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12083228105620562,\n",
       " 0.012676768527092628,\n",
       " 0.060717681061817776,\n",
       " 0.8057732693548839)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helix1/all,helix5/all,sheet/all, other/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "cellId": "n9lel7y53gsauh6pqhqog"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8791677189437944,\n",
       " 0.9873232314729073,\n",
       " 0.9392823189381823,\n",
       " 0.19422673064511603)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all-helix1)/all,(all-helix5)/all,(all-sheet)/all, (all-other)/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "cellId": "9hkt9vll1lesm91i0z982f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxqBOmOhkowI",
    "outputId": "f80659c0-a89e-4fff-97e4-94ce7f723ac8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-47b5bf3f6572>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['h1'] = '0'\n",
      "<ipython-input-50-47b5bf3f6572>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['h1_bin'] = '0'\n",
      "<ipython-input-50-47b5bf3f6572>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['h5'] = '0'\n",
      "<ipython-input-50-47b5bf3f6572>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['h5_bin'] = '0'\n",
      "<ipython-input-50-47b5bf3f6572>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sh'] = '0'\n",
      "<ipython-input-50-47b5bf3f6572>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sh_bin'] = '0'\n"
     ]
    }
   ],
   "source": [
    "data['h1'] = '0'\n",
    "data['h1_bin'] = '0'\n",
    "\n",
    "data['h5'] = '0'\n",
    "data['h5_bin'] = '0'\n",
    "\n",
    "data['sh'] = '0'\n",
    "data['sh_bin'] = '0'\n",
    "\n",
    "#data['other_bin'] = '0'\n",
    "max_protein_length = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cellId": "qsvzg3rhi9knuc6fh09a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NivOdTxnk0Qe",
    "outputId": "cabb443e-b3f2-40f0-b1df-836c20432d9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479288"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "151bepjn6nho3w8mwfxtcf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "execution_id": "d623e039-10c4-485a-baaa-bfd881756709",
    "id": "IjByrxVthGtk",
    "outputId": "53d1a351-b543-42d8-b0c2-6c64e6e9265f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "for i in range(0,data.shape[0]):\n",
    "    data['sequence_length'] = len(data['protein_chain_sequence'].iloc[i])\n",
    "    \n",
    "    if ((data['struct_class'].iloc[i] == 1) | (data['struct_class'].iloc[i] == '1')):\n",
    "        start_pos = data['init_seq_num'].iloc[i]-1\n",
    "        stop_pos = data['term_seq_num'].iloc[i]\n",
    "        data['h1'].iloc[i] = ''.ljust(min(start_pos,max_protein_length), '0').ljust(min(stop_pos,max_protein_length),'1').ljust(max_protein_length, '0')\n",
    "        \n",
    "    else:\n",
    "        data['h1'].iloc[i] = ''.ljust(max_protein_length, '0')\n",
    "        \n",
    "    if  ((data['struct_class'].iloc[i] == 5) | (data['struct_class'].iloc[i] == '5')):\n",
    "        start_pos = data['init_seq_num'].iloc[i]-1\n",
    "        stop_pos = data['term_seq_num'].iloc[i]\n",
    "        data['h5'].iloc[i] = ''.ljust(min(start_pos,max_protein_length), '0').ljust(min(stop_pos,max_protein_length), '1').ljust(max_protein_length, '0')\n",
    "    else:\n",
    "        data['h5'].iloc[i] = ''.ljust(max_protein_length, '0')\n",
    "   \n",
    "    if  data['struct_class'].iloc[i] == 'sh':\n",
    "        start_pos = data['init_seq_num'].iloc[i]-1\n",
    "        stop_pos = data['term_seq_num'].iloc[i]\n",
    "        data['sh'].iloc[i] = ''.ljust(min(start_pos,max_protein_length), '0').ljust(min(stop_pos,max_protein_length), '1').ljust(max_protein_length, '0')\n",
    "    else:\n",
    "        data['sh'].iloc[i] = ''.ljust(max_protein_length, '0')\n",
    "    \n",
    " \n",
    "    data['h1_bin'].iloc[i] = np.array([int(x) for x in  data['h1'].iloc[i]])\n",
    "    data['h5_bin'].iloc[i] = np.array([int(x) for x in  data['h5'].iloc[i]])\n",
    "    data['sh_bin'].iloc[i] = np.array([int(x) for x in  data['sh'].iloc[i]])\n",
    "    \n",
    "data\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "41pfj6sm26uz46pratq8ql",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "execution_id": "cf394422-6042-4c4d-8b0a-8b5f1f972224",
    "id": "Hj8nTPp8ktNP",
    "outputId": "4459a286-d44a-46cb-9366-3fac0c8f0a64"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "\n",
    "y_prep1 = data[['protein_chain_id','h1_bin','h5_bin','sh_bin']].groupby('protein_chain_id').sum()\n",
    "y = y_prep1\n",
    "y['y_labels'] = y['h1_bin']\n",
    "y['other'] = y['h1_bin']\n",
    "for i in range(0,y.shape[0]):\n",
    "    #print(i)\n",
    "    y['other'].iloc[i] =  y['h1_bin'].iloc[i] + y['h5_bin'].iloc[i] + y['sh_bin'].iloc[i]\n",
    "    y['other'].iloc[i] = [abs(x-1) for x in y['other'].iloc[i]]\n",
    "    y['y_labels'].iloc[i] = np.vstack((y['h1_bin'].iloc[i],y['h5_bin'].iloc[i],y['sh_bin'].iloc[i],y['other'].iloc[i])).T    \n",
    "y = y.drop(columns = ['h1_bin','h5_bin','sh_bin','other'])\n",
    "#y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "oan3hivub4my8b6efxn79",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution_id": "cd7f5977-f8db-41f0-9351-6ad439097715",
    "id": "7O98E6wyODtZ",
    "outputId": "55854323-646f-4cae-effc-72dfd1f2f474"
   },
   "outputs": [],
   "source": [
    "### X\n",
    "X_prep1 = protein_struct_loaded[['protein_chain_id','protein_chain_sequence']].groupby('protein_chain_id').agg('max')\n",
    "X_prep1['protein_chain_seq'] = X_prep1.protein_chain_sequence[:].str[:max_protein_length]\n",
    "X_prep1 = X_prep1.drop(columns = ['protein_chain_sequence'])\n",
    "#X_prep1.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "eshxeredbehgylcwcsuefo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_id": "5011a4b2-a05a-4614-8569-03074c2eaa34",
    "id": "5EoDhh5IOGeX",
    "outputId": "7663292d-4d4f-4b60-8e84-1845c955b863"
   },
   "outputs": [],
   "source": [
    "simbs = np.sum(X_prep1.protein_chain_seq)\n",
    "simbs_arr = np.array([x for x in  simbs])\n",
    "simbs_unique = np.unique(simbs_arr)\n",
    "simbs_unique = np.append('_',simbs_unique)\n",
    "simbs_unique = pd.Series(simbs_unique)\n",
    "#simbs_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tylkk5hb7ao8d9xsgaic8v",
    "execution_id": "210dad5c-d6cd-4b05-b453-6c230b538faa"
   },
   "outputs": [],
   "source": [
    "len(simbs_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jt8y3jp895scp8rp9tw3xm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution_id": "4fe12af7-8a37-46d9-b756-e653262c94be",
    "id": "Q9BaRvUTcqU-",
    "outputId": "b3195b41-a9b1-4a27-dac6-e7e2973e3eca"
   },
   "outputs": [],
   "source": [
    "X_prep2 = X_prep1.copy()\n",
    "X_prep2['chain_simbs'] = [np.empty(0,dtype=float)]*len(X_prep2) \n",
    "X_prep2['chain_simbs_indexed'] =  [np.empty(0,dtype=float)]*len(X_prep2) \n",
    "\n",
    "#добавляю столбцы A,A_chain_freq\n",
    "for s in simbs_unique:  \n",
    "    #print(s)\n",
    "    s_column = s + '_column'\n",
    "    s_count_in_protein = s + '_count_in_protein'\n",
    "    s_pssm = s + '_pssm'\n",
    "    \n",
    "    X_prep2.insert(1, s_column,  [np.empty(0,dtype=float)]*len(X_prep2))  \n",
    "    X_prep2.insert(1, s_count_in_protein,  0)\n",
    "    X_prep2.insert(1, s_pssm,  [np.empty(0,dtype=float)]*len(X_prep2))\n",
    "\n",
    "#print(X_prep2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "27fovir4y5uw05tk7j1of",
    "execution_id": "20fb1786-09f4-41a3-9ddf-294cc097b76a"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "simb_to_index = lambda x: simbs_unique[simbs_unique == x].index[0]\n",
    "simb_to_1 = lambda x : 1 if (x == s) else 0\n",
    "\n",
    "for i in range(0,X_prep2.shape[0]):\n",
    "   #print(i)\n",
    "    X_prep2['chain_simbs'].iloc[i] = np.array([x for x in  X_prep2.protein_chain_seq.iloc[i]]) \n",
    "    #print(X_prep2['chain_simbs'].iloc[i] )\n",
    "    if len(X_prep2['chain_simbs'].iloc[i] ) <  max_protein_length:\n",
    "        #dops = ['_']*(max_protein_length - len(arr_chain))\n",
    "        X_prep2['chain_simbs'].iloc[i] = np.append(X_prep2['chain_simbs'].iloc[i], \n",
    "                                                   ['_']*(max_protein_length - len(X_prep2['chain_simbs'].iloc[i])))\n",
    "\n",
    "    X_prep2['chain_simbs_indexed'].iloc[i] =np.array([simb_to_index(x) for x in  X_prep2['chain_simbs'].iloc[i]])\n",
    "\n",
    "    for s in simbs_unique: \n",
    "        s_column = s + '_column'\n",
    "        s_count_in_protein = s + '_count_in_protein'\n",
    "        X_prep2[s_column].iloc[i] = np.array([simb_to_1(x) for x in  X_prep2['chain_simbs'].iloc[i]])\n",
    "        X_prep2[s_count_in_protein].iloc[i] = sum(X_prep2[s_column].iloc[i])\n",
    "    \n",
    "#X_prep2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0h6k2z74me5alztfryjdy0m",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution_id": "da5af574-373c-4e49-9d81-c1602eaf6c8f",
    "id": "ONI4YudAP5Yj",
    "outputId": "3e981c65-61fe-4a26-e7d6-6b64adbb180e"
   },
   "outputs": [],
   "source": [
    "#X = X_prep2.drop(columns=['chain_simbs','chain_array_for_pssm'])\n",
    "X = X_prep2[['protein_chain_seq','chain_simbs_indexed']]\n",
    "#X.head(5)#.loc['1zg2_A'].chain_simbs_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2tm6sr4ijtw3lhf5dye4cd",
    "execution_id": "6786180b-3d79-41a3-9643-0188bfd2b869"
   },
   "outputs": [],
   "source": [
    "X.chain_simbs_indexed[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w7n8g77yucmwntdml5g",
    "execution_id": "e580fe98-8ed1-4b0f-966f-08219c3af988"
   },
   "outputs": [],
   "source": [
    "# аггрегирую \n",
    "SPFM = X_prep2.drop(columns =['protein_chain_seq','chain_simbs','chain_simbs_indexed']).sum()\n",
    "#SPFM.head(2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "cz8hxert32hokfqfx85kl",
    "execution_id": "4e2c4a1f-a6a2-43c6-912b-d608bdeb6c22"
   },
   "outputs": [],
   "source": [
    "all_simb_count = max_protein_length * X_prep2.shape[0]\n",
    "norm_to_log2 = lambda x : np.log2(x)\n",
    "pssm_column_array = list()\n",
    "print(pssm_column_array, type(pssm_column_array))\n",
    "for s in simbs_unique: \n",
    "    #print(s)\n",
    "    s_column = s + '_column'\n",
    "    s_count_in_protein = s + '_count_in_protein'\n",
    "    s_column_freq = s + '_column_freq'    # доля присутствия символа на каждой позиции в датасете\n",
    "    s_overall_frequences = s + '_overall_frequences'  #доля присутствия символа вообще в датасете\n",
    "    s_normalized = s + '_normalized'\n",
    "    s_log2 = s + '_log2'\n",
    "    column_pssm = s + '_pssm'  #для создания списка столбцов, которые потом надо будет сложить в X_prep2\n",
    "    \n",
    "    SPFM[s_column_freq] = SPFM[s_column] / X_prep2.shape[0]\n",
    "    SPFM[s_overall_frequences] = SPFM[s_count_in_protein] / all_simb_count\n",
    "    SPFM[s_normalized] = SPFM[s_column_freq] / SPFM[s_overall_frequences] + 0.01\n",
    "    #print(SPFM[[s_column,s_normalized]])\n",
    "    SPFM[s_log2]= np.log2(SPFM[s_normalized])   #([norm_to_log2(x) for x in  SPFM[s_normalized]])\n",
    "    #print(SPFM[s_log2])\n",
    "    \n",
    "    pssm_column_array.append(column_pssm)\n",
    "\n",
    "#SPFM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bpw23gklwbcp3bf1phrki",
    "execution_id": "cb7f4c36-c124-448c-bbfb-f9dd76cd0e39"
   },
   "outputs": [],
   "source": [
    "SPFM = pd.DataFrame(SPFM).T\n",
    "#print(SPFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e9k1pf7ygksv88f37gjmn",
    "execution_id": "0179e97e-ab5f-4232-95db-d05b83873d3f"
   },
   "outputs": [],
   "source": [
    "X_prep2['chain_pssm'] = X_prep2['chain_simbs_indexed']\n",
    "X_prep2['chain_pssm_sum'] = [np.empty(0,dtype=float)]*len(X_prep2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1co9ksk764gycde85zsggo",
    "execution_id": "3aad015a-a5a1-4de2-b9fe-49ef7f61811f"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "# получаю PSSM \n",
    "#simb_to_pos = lambda spos : SPFM[s+'_log2'] if (spos == s) \n",
    "#SPFM = pd.DataFrame(SPFM).T\n",
    "#X_prep2['chain_pssm'] = X_prep2['chain_simbs_indexed']\n",
    "#X_prep2['chain_pssm_sum'] = [np.empty(0,dtype=float)]*len(X_prep2) \n",
    "for i in range(0,X_prep2.shape[0]):\n",
    "    #(i, X_prep2.chain_simbs.iloc[i])\n",
    "    #print(X_prep2.chain_simbs.iloc[i].shape[0])\n",
    "    #X_prep2['chain_pssm'].iloc[i] = None\n",
    "    for s in simbs_unique: \n",
    "        s_pssm = s + '_pssm'\n",
    "        s_column = s + '_column'\n",
    "        s_log2 = s + '_log2'\n",
    "        X_prep2[s_pssm].iloc[i] = np.array(X_prep2[s_column].iloc[i] * SPFM[s_log2][0])\n",
    "        X_prep2['chain_pssm'].iloc[i] = np.vstack((X_prep2['chain_pssm'].iloc[i],X_prep2[s_pssm].iloc[i]))\n",
    "      #  X_prep2['chain_pssm_sum'].iloc[i] = X_prep2[['chain_pssm_sum',s_pssm]].iloc[i].sum(axis=1)\n",
    "        \n",
    "    X_prep2['chain_pssm'].iloc[i] = X_prep2['chain_pssm'].iloc[i][1:]\n",
    "    X_prep2['chain_pssm_sum'].iloc[i] = X_prep2.chain_pssm.iloc[i].sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "p51ciaukmc8z3egcitebuj",
    "execution_id": "c439999a-f3a4-4f35-8c02-2db65f7ffe45"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "PSSM = X_prep2[['protein_chain_seq','chain_pssm_sum']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "72m1po1xc9pefin3weabiv",
    "execution_id": "27efc87b-82ea-4e08-be63-aca600fd06db",
    "id": "5NBq6W4RhGtr"
   },
   "source": [
    "## Построение нейронной сети для предсказания вторичных структур по последовательности аминокислотных остатков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vvdnhz5ujecamsli4pbvpr",
    "execution_id": "416078ed-1440-4dfd-ab5a-5779b79bfd29",
    "id": "2JsUlFSphGtt"
   },
   "outputs": [],
   "source": [
    "dataX = X\n",
    "datay = y\n",
    "dataPSSM = PSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "sz7xsa6tn9x0m1wyr225l",
    "execution_id": "5c6da1d8-5419-4c99-83cf-12d442d541a0",
    "id": "0Gerrdc0hGt1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fmto5lgf27pfodrcufgxl",
    "execution_id": "6e619778-a318-4301-a330-04abe2bd9ef9",
    "id": "HAfL2jj1hGt4"
   },
   "outputs": [],
   "source": [
    "class ChainDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.Xs = dataX\n",
    "        self.ys = datay        \n",
    "        self.PSSM = dataPSSM\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Xs)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        chain_id = self.Xs.index[idx]\n",
    "        chain_sequence = self.Xs.protein_chain_seq[idx]\n",
    "        X = self.Xs.chain_simbs_indexed[idx]   #700x1        \n",
    "        y = self.ys.y_labels[idx] #700x2\n",
    "        PSSM = self.PSSM.chain_pssm_sum[idx]      \n",
    "        # print(y)\n",
    "        sample = {'chain_id': chain_id, 'chain_sequence': chain_sequence ,'inputs': X, 'labels': y, 'pssm': PSSM}\n",
    "        return(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rizhi678mzjjhq57ksoqs",
    "execution_id": "aa4cbfec-7e70-481d-b596-b2709d406cab",
    "id": "05ewwJOehGt5"
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ubhosd2g7g642rdufhfij",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_id": "21654623-d6ca-483f-91e5-18157c3c1d95",
    "id": "bkzTklbXhGt6",
    "outputId": "d202a613-cd06-4367-c2c7-514f6164cbd5"
   },
   "outputs": [],
   "source": [
    "dataset = ChainDataset(transform = data_transform)\n",
    "dataset.__getitem__(0)['inputs'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "63ux17zzjfyp591nuynymg",
    "execution_id": "ee96e5f0-e770-4679-b74e-fd76fe40bfb4",
    "id": "eSqH_C5rhGt8"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, \n",
    "                                                    [train_size, test_size], \n",
    "                                                    generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jw8qrgt3rmplg69iibzaq",
    "execution_id": "32835387-1b47-48fc-bd25-4340e0322542"
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hgtyuqhp56vld8pyu1vdi",
    "execution_id": "46225ba8-9d20-41ea-a824-eac12a43573d",
    "id": "_vKrlQcUhGt_"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3jrgu0bvb0t1yok8bzyl3m",
    "execution_id": "a0a0f3dd-c639-45b8-a205-6a003b8103a2",
    "id": "tzlwxSgohGuB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3aj1uz0vx10y4i3q8ii1br",
    "execution_id": "722e3cd9-2e7b-40c9-aefa-c73a0b462f41",
    "id": "Rg0Q71E2hGuC"
   },
   "outputs": [],
   "source": [
    "class  ChainModel(nn.Module):\n",
    "    def __init__(self):         \n",
    "        super().__init__()\n",
    "               \n",
    "        self.x_embedding = nn.Embedding(24, 47)\n",
    "        self.pssm_embedding = nn.Embedding(24, 24)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=71, out_channels=68, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU())\n",
    "        self.conv7 = nn.Sequential(nn.Conv1d(in_channels=71, out_channels=64, kernel_size=7, padding=3),\n",
    "                                   nn.ReLU())\n",
    "        self.conv11 = nn.Sequential(nn.Conv1d(in_channels=71, out_channels=60, kernel_size=11, padding=5),\n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        self.iL1= 192 # self.input_size_encoder\n",
    "        self.oL1= 192 # self.hidden_size\n",
    "        self.iL2= self.iL1*2 + self.oL1*2 #(Bidirectional)\n",
    "        self.oL2= self.iL2 \n",
    "        self.iL3= self.oL2*2 + self.oL1*2 + self.iL1*2   #(Bidirectional)\n",
    "        self.oL3= self.iL3\n",
    "\n",
    "        self.gru1 = nn.Sequential(nn.Dropout(p=0.2, inplace=False), nn.GRU(input_size=self.iL1, hidden_size=self.oL1, batch_first=True, bidirectional=True))#, nn.Dropout(p=0.2, inplace=False) ) \n",
    "        self.gru2 = nn.Sequential(nn.Dropout(p=0.2, inplace=False), nn.GRU(input_size=self.iL2, hidden_size=self.oL2, batch_first=True, bidirectional=True))#, nn.Dropout(p=0.2, inplace=False) )  \n",
    "        self.gru3 = nn.Sequential(nn.Dropout(p=0.2, inplace=False), nn.GRU(input_size=self.iL3, hidden_size=self.oL3, batch_first=True, bidirectional=True))#, nn.Dropout(p=0.2, inplace=False) ) \n",
    "    \n",
    "        \n",
    "        #input_size – The number of expected features in the input x\n",
    "        #hidden_size – The number of features in the hidden state h\n",
    "        #num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two GRUs together to form a stacked GRU, with the second GRU taking in outputs of the first GRU and computing the final results. Default: 1\n",
    "        #bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "        #batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False\n",
    "        #dropout – If non-zero, introduces a Dropout layer on the outputs of each GRU layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "        #bidirectional – If True, becomes a bidirectional GRU. Default: False\n",
    "        \n",
    "        self.detection = nn.Sequential( nn.Linear(4608, 128),   #700x192 =      \n",
    "                                        nn.BatchNorm1d(max_protein_length),\n",
    "                                        nn.Linear(128, 4),\n",
    "                                        nn.BatchNorm1d(max_protein_length),  \n",
    "                                        nn.Softmax(dim = 2)                         \n",
    "                                    )\n",
    "                                 \n",
    "                                 \n",
    "    def forward(self, x, PSSM):\n",
    "        \n",
    "             \n",
    "        x_emb = self.x_embedding(x) \n",
    "      \n",
    "        PSSM_emb = self.pssm_embedding(x) \n",
    "      \n",
    "        \n",
    "        x_emb = torch.cat((x_emb.float(), PSSM_emb.float()),dim=2)#  print(\"x_emb\",x_emb)\n",
    "        ####print(x_emb.shape)\n",
    "        #print(x_emb)\n",
    "        x_emb = x_emb.permute(0,2,1)\n",
    "        #print(x_emb.shape)\n",
    "        #print(x_emb)\n",
    "        xc3 = self.conv3(x_emb)  # barch_size X 700 X 71 -> barch_size X 700 X 68\n",
    "        xc7 = self.conv7(x_emb)   \n",
    "        xc11 = self.conv11(x_emb)  \n",
    "        \n",
    "        x_conv = torch.cat((xc3, xc7, xc11),1)\n",
    "        x_conv = x_conv.permute(0,2,1)\n",
    "\n",
    "        output1, h_n1 = self.gru1(x_conv) \n",
    "        fw1_res = torch.cat((x_conv,output1[:,:,self.oL1:]), dim=2) # x,L1\n",
    "        bw1_res = torch.cat((output1[:,:,:self.oL1],x_conv) ,dim=2) # L1,x\n",
    "        output1_residual = torch.cat((fw1_res,bw1_res),dim=2)\n",
    "        output2, h_n2 = self.gru2(output1_residual)\n",
    "        \n",
    "        fw2_res = torch.cat((x_conv,output1[:,:,self.oL1:],output2[:,:,self.oL2:]),dim=2) # x,L1,L2\n",
    " \n",
    "        bw2_res = torch.cat((output2[:,:,:self.oL2],output1[:,:,:self.oL1],x_conv),dim=2) # L2,L1,x\n",
    "        output2_residual = torch.cat((fw2_res,bw2_res),dim=2)\n",
    "        output3, h_n3 = self.gru3(output2_residual) \n",
    "    \n",
    "        x_detect = self.detection(output3)\n",
    "        return x_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k5z0ep30o6p00k5wmilmrq2",
    "execution_id": "92bbc684-c0b0-4373-9aa1-93616d476aa8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5a1hfgpwkga10pnaiifdtqd",
    "execution_id": "5c8a0334-707a-4626-9edc-af539bea1f6c",
    "id": "5vDisHQOhGuD"
   },
   "outputs": [],
   "source": [
    "def train_nn(trainloader, model, opt, loss_fn):\n",
    "    stime = time.monotonic()\n",
    "    loss_train = []\n",
    "    accuracy_train = []  \n",
    "    accuracy_train_by_class = []\n",
    "   \n",
    "    model.train()\n",
    "      \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs = data.get('inputs')\n",
    "        labels = data.get('labels')           \n",
    "        pssm = data.get('pssm')    \n",
    "        \n",
    "        predictions = model(inputs, pssm) \n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions_max = torch.argmax(predictions,dim =2)\n",
    "            labels_max = torch.argmax(labels,dim =2)     \n",
    "           \n",
    "            accuracy = accuracy_weighted(predictions.permute(0,2,1), labels_max)\n",
    "            accuracy_by_class = accuracy_none(predictions.permute(0,2,1), labels_max)\n",
    "                        \n",
    "        \n",
    "        loss =  loss_fn(predictions.permute(0,2,1), labels_max).mean()\n",
    "        \n",
    "      \n",
    "        print(i, \"TRAIN   LOSS\", loss, \" acc_weighted\", accuracy,  \" acc_by_class\", accuracy_by_class) #, \"loss_none\", loss_none)\n",
    "        opt.zero_grad()        \n",
    "        loss.mean().backward()   \n",
    "        opt.step()\n",
    "    \n",
    "        loss_train.append(loss.item())\n",
    "        accuracy_train.append(accuracy.item())        \n",
    "        accuracy_train_by_class.append(accuracy_by_class) \n",
    "        \n",
    "\n",
    "    return model, loss_train, accuracy_train, accuracy_train_by_class \n",
    "\n",
    "\n",
    "def eval_nn(testloader, model, loss_fn):\n",
    "    loss_test = []\n",
    "    accuracy_test = []    \n",
    "    accuracy_test_by_class = []\n",
    " \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "\n",
    "            inputs = data.get('inputs')\n",
    "            labels = data.get('labels')\n",
    "            pssm = data.get('pssm')\n",
    "\n",
    "            predictions = model(inputs,pssm) \n",
    "            predictions_max = torch.argmax(predictions,dim =2)\n",
    "\n",
    "            labels_max = torch.argmax(labels,dim =2)\n",
    "         \n",
    "            loss =  loss_fn(predictions.permute(0,2,1), labels_max).mean()\n",
    "            accuracy = accuracy_weighted(predictions.permute(0,2,1), labels_max)\n",
    "            accuracy_by_class = accuracy_none(predictions.permute(0,2,1), labels_max)              \n",
    "            \n",
    "            print( i ,\"TEST LOSS\", loss, \" acc_weighted\", accuracy,  \" acc_by_class\", accuracy_by_class)\n",
    "          \n",
    "            loss_test.append(loss.item())\n",
    "            accuracy_test.append(accuracy.item())\n",
    "            accuracy_test_by_class.append(accuracy_by_class)         \n",
    "            \n",
    "    return loss_test, accuracy_test, accuracy_test_by_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7ndcj7cfr0g747nbdekugb",
    "execution_id": "c13b2796-6dc5-4a6b-8b21-ceb2f0f1dc2e",
    "id": "HzDI2qbphGuE"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, trainloader, testloader, opt, loss_fn, max_epochs=2):\n",
    "   \n",
    "    loss_epoch_train = []\n",
    "    loss_epoch_test = []\n",
    "    acc_epoch_train = []\n",
    "    acc_epoch_test = []\n",
    "    acc_epoch_train_by_class = []\n",
    "    acc_epoch_test_by_class = []\n",
    "    \n",
    "    for epoch in range(max_epochs):        \n",
    "        model, loss_train, accuracy_train, accuracy_train_by_class = train_nn(trainloader, model, opt, loss_fn)\n",
    "        loss_test, accuracy_test, accuracy_test_by_class  = eval_nn(testloader, model, loss_fn)\n",
    "\n",
    "     \n",
    "        loss_epoch_train.append(np.mean(loss_train))\n",
    "        loss_epoch_test.append(np.mean(loss_test))\n",
    "\n",
    "        acc_epoch_train.append(np.mean(accuracy_train))\n",
    "        acc_epoch_test.append(np.mean(accuracy_test))\n",
    "\n",
    "        acc_epoch_train_by_class.append(torch.mean(torch.reshape(torch.cat(accuracy_train_by_class,0),(-1,4)), axis = 0))\n",
    "        acc_epoch_test_by_class.append(torch.mean(torch.reshape(torch.cat(accuracy_test_by_class,0),(-1,4)), axis = 0))\n",
    "        \n",
    "        print(f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {loss_epoch_train[-1]:.5f}\\t'\n",
    "                  f'Test loss: {loss_epoch_test[-1]:.5f}\\t'\n",
    "                  f'Train accuracy: { acc_epoch_train[-1]:.2f}\\t'\n",
    "                  f'Test accuracy: { acc_epoch_test[-1]:.2f} ') #\\t'\n",
    "                \n",
    "    return loss_epoch_train, loss_epoch_test, acc_epoch_train, acc_epoch_test, acc_epoch_train_by_class, acc_epoch_test_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qzm8aci6ppbd7esdhyhnp",
    "execution_id": "db349764-41c3-40ab-ac39-2c2af8d6d99c",
    "id": "z8CaX1X_hGuF"
   },
   "outputs": [],
   "source": [
    "model_chain = ChainModel()\n",
    "weights = torch.tensor([0.88,  0.99,  0.94,  0.19])\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=weights,reduction='none')#size_average=False,reduction='sum')#reduction='none')\n",
    "optimizer = torch.optim.Adam(model_chain.parameters(), lr=0.0003) # lr=0.00005\n",
    "\n",
    "import torchmetrics \n",
    "from torchmetrics import Accuracy\n",
    "accuracy_none = Accuracy(average = 'none', num_classes = 4,  mdmc_average = 'samplewise')\n",
    "accuracy_weighted = Accuracy(average = 'weighted', num_classes = 4,  mdmc_average = 'samplewise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k6m0a8hy1limlg7e0zswl",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution_id": "77b6c873-2012-4484-b972-363ff93d2ac5",
    "id": "hbSswGjKhGuG",
    "outputId": "5b705614-b2cd-453c-aa18-ecdc792fc61b"
   },
   "outputs": [],
   "source": [
    "loss_epoch_train, loss_epoch_test, acc_epoch_train, acc_epoch_test, acc_epoch_train_by_class, acc_epoch_test_by_class = training_loop(model_chain, train_loader, test_loader, optimizer, loss_function, max_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "37l50j5cxcfsapb16maedo",
    "execution_id": "28e298b5-bad6-4ee3-a776-e9b2985b58fe",
    "id": "JAgbdnPYhGuG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot(loss_epoch_train, loss_epoch_test, acc_epoch_train, acc_epoch_test, acc_epoch_train_by_class, acc_epoch_test_by_class ):\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(20, 12))\n",
    "\n",
    "    ax[0,0].plot(loss_epoch_train, label='Train loss')\n",
    "    ax[0,0].plot(loss_epoch_test, label='Test loss')\n",
    "    ax[0,0].legend()\n",
    "    ax[0,0].grid()   \n",
    "    ax[0, 0].set_title('Loss by epochs')\n",
    "\n",
    "    ax[0,1].plot(acc_epoch_train, label='Train accuracy')\n",
    "    ax[0,1].plot(acc_epoch_test, label='Test accuracy')\n",
    "    ax[0,1].legend()\n",
    "    ax[0,1].grid()\n",
    "    ax[0, 1].set_title('Accuracy by epochs')\n",
    "    \n",
    "    ax[1][0].plot(acc_epoch_train_by_class[0], label='Train class0')    \n",
    "    ax[1][0].plot(acc_epoch_train_by_class[1], label='Train class1')    \n",
    "    ax[1][0].plot(acc_epoch_train_by_class[2], label='Train class2')    \n",
    "    ax[1][0].plot(acc_epoch_train_by_class[3], label='Train class3')    \n",
    "    ax[1][0].legend()\n",
    "    ax[1][0].grid()   \n",
    "    ax[1, 0].set_title('Accuracy by classes. Train')\n",
    "\n",
    "\n",
    "    ax[1][1].plot(acc_epoch_test_by_class[0], label='Test class0')\n",
    "    ax[1][1].plot(acc_epoch_test_by_class[1], label='Test class1')\n",
    "    ax[1][1].plot(acc_epoch_test_by_class[2], label='Test class2')\n",
    "    ax[1][1].plot(acc_epoch_test_by_class[3], label='Test class3')\n",
    "    ax[1][1].legend()\n",
    "    ax[1,1].grid()\n",
    "    ax[1, 1].set_title('Accuracy by classes. Test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "iisas6fpdqispzkdqfmi",
    "execution_id": "1c824045-33f9-4f25-84db-6e773d7e9c42"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot(loss_epoch_train, loss_epoch_test, acc_epoch_train, acc_epoch_test, acc_epoch_train_by_class, acc_epoch_test_by_class)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Khotlyannik 2structures detection colab_part.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "91cacde4-2389-4eb3-a90d-303cfd6669a6",
  "notebookPath": "Khotlyannik_2structures_detection_07.08.2022.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
